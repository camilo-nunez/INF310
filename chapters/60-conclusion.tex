\chapter{Conclusion}
This research undertakes a comprehensive analysis of feature fusion behaviors, particularly in the local and global context feature variables, within the specialized domains of object detection and instance segmentation. Central to this investigation is the development and implementation of the \textit{Context Aggregation with Bi-Feature Pyramid Network}(CABiFPN), a novel fusion neck architecture designed to enhance object detection efficacy. Through a rigorous comparison with the conventional \textit{Bi-Feature Pyramid Network }(BiFPN), the CABiFPN demonstrates markedly superior performance in various object detection tasks.\\

Utilizing visual explanation methodologies such as Ablation Class Activation Mapping (Ablation CAM) and imputation-based techniques, we substantiate that CABiFPN-enabled models exhibit a higher proficiency in recognizing and exploiting contextual features, thereby contributing to enhanced object detection and segmentation accuracies.
Our empirical findings reveal that models incorporating the CABiFPN architecture surpass those utilizing the standard BiFPN architecture, particularly in the realm of bounding box and mask predictions. For example, the EfficientNetV2-M model outfitted with neck CABiFPN excels in bounding box predictions, whereas the ConvNeXt-S architecture coupled with neck CABiFPN yields superior outcomes in mask predictions. However, it should be noted that the increased number of parameters in CABiFPN introduces a higher level of computational complexity. While this confirms earlier research, the added complexity appears to be a contributing factor to the model's enhanced capability to capture intricate patterns.\\

Furthermore, the CABiFPN architecture manifests a robust capacity for identifying objects across a range of scales. Contrarily, models built upon the BiFPN neck encounter difficulties, especially when faced with objects possessing smaller surface areas. CABiFPN neck models exhibit a broader efficacy, identifying instances across diverse contexts and poses.
In terms of feature fusion strategies, different models reveal heterogeneous approaches. For instance, when configured with both necks BiFPN and CABiFPN, the EfficientNetV2-M model displays distinct feature fusion behaviors in its early and later layers. CABiFPN tends to capitalize more effectively on high-level contextual features compared to BiFPN.
Despite these advances, certain limitations persist across all evaluated models and architectures. One universal issue is the suboptimal detection of objects with smaller surface areas, such as \texttt{'backpacks'} and \texttt{'skis'} particularly in cluttered or crowded scenes. Additionally, certain configurations like InternImage-S + CABiFPN and ConvNeXt-S + CABiFPN produce increased artifacts in mask segmentation tasks.\\

In summary, both the general and specific objectives of this research were fully realized. Quantitative findings were further bolstered through the utilization of Ablation CAM and imputation techniques, providing a nuanced understanding of variations in model performance.

\section{Future Work}
Several avenues for future research are delineated below:
\begin{itemize}
    \item Future investigations should assess the feasibility of sibling training with different optimization algorithms, such as a 1x schedule training using AdamW and another employing Stochastic Gradient Descent with Warm Restarts~\cite{DBLP:journals/corr/LoshchilovH16a}.
    \item As discussed in Section \ref{subsubsec:40:train}, we opted to resize images from the COCO dataset to the original dimensions of $224 \times 224$ as used in the ImageNet dataset. A more comprehensive analysis should explore varying input sizes to understand the behavior of multi-scale variations in the images. Alternatively, one may choose to not resize the dataset, using the original COCO image dimensions.
    \item It is imperative to optimize the complexity of Context Aggregator Units and FMBConvCA Blocks. A potential approach might be to follow the research conducted by \textit{Zhuang Liu et al.}, as discussed in their work on ConvNeXt~\cite{liu2022convnet} and outlined in Section \ref{sec:rw:convnext}.
    \item Future work should also evaluate the performance of CABiFPN architectures using more balanced datasets, such as Open Images~\cite{OpenImages2}.
\end{itemize}